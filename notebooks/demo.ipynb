{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchdms\n",
    "import torchdms.model\n",
    "from dms_variants.binarymap import BinaryMap\n",
    "from torchdms.analysis import Analysis\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[aa_func_scores, wtseq] = torchdms.binarymap.from_pickle_file(\"../_ignore/aa_func_scores_and_wtseq.pkl\")\n",
    "[aa_func_scores, wtseq] = torchdms.binarymap.from_pickle_file(\"../_ignore/gb1.pkl\")\n",
    "aa_func_scores[\"n_aa_substitutions\"] = [len(s.split()) for s in aa_func_scores[\"aa_substitutions\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split things up so that we get `per_mutation_count_variants` variants per mutation count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_mutation_count_variants = 250\n",
    "mutation_count_limit = 5\n",
    "\n",
    "aa_func_scores[\"in_test\"] = False\n",
    "\n",
    "for mutation_count, grouped in aa_func_scores.groupby(\"n_aa_substitutions\"):\n",
    "    if mutation_count > mutation_count_limit:\n",
    "        break\n",
    "    to_put_in_test = grouped.sample(n=per_mutation_count_variants).index\n",
    "    aa_func_scores.loc[to_put_in_test, \"in_test\"] = True\n",
    "\n",
    "max_mutation_count = min(mutation_count_limit, max(aa_func_scores[\"n_aa_substitutions\"]))   \n",
    "assert aa_func_scores[\"in_test\"].sum() == per_mutation_count_variants * max_mutation_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record the number of mutations for our held-out set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmap_split(in_test):\n",
    "    return BinaryMap(\n",
    "            aa_func_scores.loc[aa_func_scores[\"in_test\"] == in_test,], \n",
    "            expand=True, wtseq=wtseq)\n",
    "\n",
    "test_data = bmap_split(True)\n",
    "train_data = bmap_split(False)\n",
    "\n",
    "assert test_data.nvariants == aa_func_scores[\"in_test\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchdms.model.SingleSigmoidNet(input_size=train_data.binarylength, hidden1_size=1)\n",
    "analysis = Analysis(model, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "analysis.train(criterion, 300)\n",
    "pd.Series(analysis.losses).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analysis.evaluate(test_data)\n",
    "results[\"n_aa_substitutions\"] = \\\n",
    "    aa_func_scores.loc[aa_func_scores[\"in_test\"] == True, \"n_aa_substitutions\"].reset_index(drop=True)\n",
    "results.plot.scatter(x=\"Observed\", y=\"Predicted\", c = results[\"n_aa_substitutions\"], cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.corr().iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
